# %% [markdown]
# # Yelp Review Analysis
# Sarthak Arora
# 

# %% [markdown]
# # 1. Overall Project Objectives  

# %% [markdown]
# Yelp is an application to provide the platform for customers to write reviews and provide a star-rating. A research indicates that a one-star increase led to 59% increase in revenue of independent restaurants. Therefore, we see great potential of Yelp dataset as a valuable insights repository.
# 
# The main purpose of our project is to conduct thorough analysis on 7 different cuisine types of restaurants which are Korean, Japanese, Chinese, Vietnamese,Thai, French and Italian, figure out what makes a good restaurant and what concerns customers, and then make recommendations of the future improvement and profit growth. Specifically, we will mainly analyze customers' reviews and figure out reasons why customers love or dislike the restaurant. For example, there may be great reviews primarily due to the friendly service, or negative reviews about high price. Meanwhile, we will also compare among those 7 different cuisine types and figure out differences from reviews and gain valuable insights to make customized recommendations to different types of restaurants. 

# %% [markdown]
# # 2. Description of Data

# %% [markdown]
# The Yelp dataset is downloaded from Kaggle website. In total, there are 5,200,000 user reviews, information on 174,000 business. we will focus on two tables which are business table and review table. Attributes of business table are as following:
# 
# * business_id: ID of the business 
# * name: name of the business
# * neighborhood 
# * address: address of the business
# * city: city of the business
# * state: state of the business
# * postal_code: postal code of the business
# * latitude: latitude of the business
# * longitude: longitude of the business
# * stars: average rating of the business
# * review_count: number of reviews received
# * is_open: 1 if the business is open, 0 therwise
# * categories: multiple categories of the business
# 
# Attribues of review table are as following:
# * review_id: ID of the review
# * user_id: ID of the user
# * business_id: ID of the business
# * stars: ratings of the business
# * date: review date
# * text: review from the user
# * useful: number of users who vote a review as usefull
# * funny: number of users who vote a review as funny
# * cool: number of users who vote a review as cool

# %% [markdown]
# # 3. Direction of Analysis 

# %% [markdown]
# 
# **Exploratory data  analysis**
# * Count the number of each cuisine type of restaurants
# * Count the number of reviews in each cuisine type of restaurants
# * Visualize the distribution of restaurants according to the ratings and cuisine types of restaurants.
# 
# **Review Analysis**
# * Clean the category column in business table into different cuisine types of restaurants and find out how the reviews can help this type of restaurants improve in the future.
# * Refer the business id in business table to review table, collect all the reviews of this type of restaurants and perform sentiment analysis to analyze frequent words in positive and negative reviews.
# * Implement SVM model to get relatively positive and negative words and get score of each word.
# * Get top 10 positive words and negative words in each cuisine type of restaurants in order to figure out the reason of high score and low score.
# * Compare among different types of restaurants to figure out the advantages and disadvantages, then we can generate a series of recommendations to this type of restaurants for the future development.
# * Overall, recommendations may have different topics which is but not limited to service, food, or decoration, etc. Our analysis is generally based on review words which we can tell from such as rude, overpriced, and slow to find out which aspect in this type of restaurants that they could improve.

# %% [markdown]
# # 4.  Summary of Progress 

# %% [markdown]
# **Selection and Filtering**
# * Filter out 50 states of US.  
# * Filter out all restaurants of US. 
# 
# **Cleaning**
# * Categorize all restaurants by cuisine type using the matching keywords.  
# * Delete all records with null category. 
# * Remove quotation marks of name and address columns.  
# * Label restaurants above rating of 4 as positive, below rating 3 label as negative, label rating 3 as neural.  
# * Drop rows with neural label.
# * Apply 'bag of words': the frequencies of various words appeared in each review as features and conduct SVM model to get score of each word.  
# 		
# **Reshaping and Reindexing**
# * Reindex the data frame.  
# * Build a new column to input the new category name and delete the previous column.  
# * Convert array to dataframe. 
# 		
# **Visualization**
# * Visualize the distribution of restaurants and reviews by category using seaborn.  
# * Visualize the distribution of restaurants and reviews by rating. 
# * Visualize top 10 negative words and positive words in each cuisine type.
# 
# **Manipulation**
# * Get a 'polarity score' (a value that reflects the polarity of sentiment) towards each restaurant category, the sentiment score of each word was first multiplied by its frequency, and then normalized by the total number of reviews for the specific category of restaurants.   
# 
# **Merging multiple data sets**
# * Merge business table and review.  

# %% [markdown]
# # 5. Progress in Coding 

# %% [markdown]
# ## Data Preparation

# %%
import pandas as pd
import seaborn as sns
%pylab inline
pd.set_option('display.max_columns',None)
pd.options.display.max_seq_items = 2000
pd.set_option('display.height', 1000)
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
import requests, re
import pandas as pd
import seaborn as sns
import nltk
import string, itertools
from collections import Counter, defaultdict
from nltk.text import Text
from nltk.probability import FreqDist
from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from gensim.corpora.dictionary import Dictionary
from gensim.models.tfidfmodel import TfidfModel
from sklearn.cluster import KMeans
from wordcloud import WordCloud

# %% [markdown]
# ### Clean Yelp_business dataset 

# %%
business = pd.read_csv('yelp_business.csv')
business.head()

# %%
## drop unuseful column 'neighborhood' 
business.drop(['neighborhood'], axis=1, inplace=True)

## remove quotation marks in name and address column
business.name=business.name.str.replace('"','')
business.address=business.address.str.replace('"','')

## filter restaurants of US
states = ["AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DC", "DE", "FL", "GA", 
          "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", 
          "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", 
          "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", 
          "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY"]
usa=business.loc[business['state'].isin(states)]
business.head()

# %%
## select all restaurants in USA
us_restaurants=usa[usa['categories'].str.contains('Restaurants')]

## select out 16 cuisine types of restaurants and rename the category
us_restaurants.is_copy=False
us_restaurants['category']=pd.Series()
us_restaurants.loc[us_restaurants.categories.str.contains('American'),'category'] = 'American'
us_restaurants.loc[us_restaurants.categories.str.contains('Mexican'), 'category'] = 'Mexican'
us_restaurants.loc[us_restaurants.categories.str.contains('Italian'), 'category'] = 'Italian'
us_restaurants.loc[us_restaurants.categories.str.contains('Japanese'), 'category'] = 'Japanese'
us_restaurants.loc[us_restaurants.categories.str.contains('Chinese'), 'category'] = 'Chinese'
us_restaurants.loc[us_restaurants.categories.str.contains('Thai'), 'category'] = 'Thai'
us_restaurants.loc[us_restaurants.categories.str.contains('Mediterranean'), 'category'] = 'Mediterranean'
us_restaurants.loc[us_restaurants.categories.str.contains('French'), 'category'] = 'French'
us_restaurants.loc[us_restaurants.categories.str.contains('Vietnamese'), 'category'] = 'Vietnamese'
us_restaurants.loc[us_restaurants.categories.str.contains('Greek'),'category'] = 'Greek'
us_restaurants.loc[us_restaurants.categories.str.contains('Indian'),'category'] = 'Indian'
us_restaurants.loc[us_restaurants.categories.str.contains('Korean'),'category'] = 'Korean'
us_restaurants.loc[us_restaurants.categories.str.contains('Hawaiian'),'category'] = 'Hawaiian'
us_restaurants.loc[us_restaurants.categories.str.contains('African'),'category'] = 'African'
us_restaurants.loc[us_restaurants.categories.str.contains('Spanish'),'category'] = 'Spanish'
us_restaurants.loc[us_restaurants.categories.str.contains('Middle_eastern'),'category'] = 'Middle_eastern'
us_restaurants.category[:20]

# %%
## drop null values in category, delete original column categories and reset the index
us_restaurants=us_restaurants.dropna(axis=0, subset=['category'])
del us_restaurants['categories']
us_restaurants=us_restaurants.reset_index(drop=True)
us_restaurants.head(10)

# %%
## check total number of us restaurants
us_restaurants.shape

# %%
## check whether has duplicated business id
us_restaurants.business_id.duplicated().sum()

# %%
## check the datatype
us_restaurants.dtypes

# %%
## check missing values
us_restaurants.isnull().sum()

# %% [markdown]
# ### Clean yelp_review dataset

# %%
## load review table
review = pd.read_csv('yelp_review.csv')
review.head()

# %%
## check missing values
review.isnull().sum()

# %%
## check duplicates of review_id
review.review_id.duplicated().sum()

# %% [markdown]
# ### Merge two datasets and get new dataframe restaurants_reviews

# %%
## merge business table and review table
restaurants_reviews = pd.merge(us_restaurants, review, on = 'business_id')

## update column names
restaurants_reviews.rename(columns={'stars_x':'avg_star','stars_y':'review_star'}, inplace=True)

## add column of number of words in review and label of negative and postive reviews
restaurants_reviews['num_words_review'] = restaurants_reviews.text.str.replace('\n',''). \
                                          str.replace('[!"#$%&\()*+,-./:;<=>?@[\\]^_`{|}~]','').map(lambda x: len(x.split()))
    

# %%
## add column of number of words in review and label of negative and postive reviews
restaurants_reviews['num_words_review'] = restaurants_reviews.text.str.replace('\n',''). \
                                          str.replace('[!"#$%&\()*+,-./:;<=>?@[\\]^_`{|}~]','').map(lambda x: len(x.split()))

# %%
# label reviews as positive or negative
restaurants_reviews['labels'] = ''
restaurants_reviews.loc[restaurants_reviews.review_star >=4, 'labels'] = 'positive'
restaurants_reviews.loc[restaurants_reviews.review_star ==3, 'labels'] = 'neural'
restaurants_reviews.loc[restaurants_reviews.review_star <3, 'labels'] = 'negative'

# drop neutral reviews for easy analysis
restaurants_reviews.drop(restaurants_reviews[restaurants_reviews['labels'] =='neural'].index, axis=0, inplace=True)
restaurants_reviews.reset_index(drop=True, inplace=True)

restaurants_reviews.head()

# %% [markdown]
# ## Exploratory Data Analysis

# %% [markdown]
# ### Restaurants Distribution

# %% [markdown]
# #### Distribution of restaurants in each category

# %%
plt.style.use('ggplot')

# %%
plt.figure(figsize=(11,7))
grouped = us_restaurants.category.value_counts()
sns.countplot(y='category',data=us_restaurants, 
              order = grouped.index, palette= sns.color_palette("RdBu_r", len(grouped)))
plt.xlabel('Number of restaurants', fontsize=14, labelpad=10)
plt.ylabel('Category', fontsize=14)
plt.title('Count of Restaurants by Category', fontsize=15)
plt.tick_params(labelsize=14)
for  i, v in enumerate(us_restaurants.category.value_counts()):
    plt.text(v, i+0.15, str(v), fontweight='bold', fontsize=14)

# %% [markdown]
# Categories in dark blue color have the largest number of restaurants. On the contrary, categories in dark red color have the least number of restaurants. The top 5 type of restaurants are American, Mexican, Italian, Chinese and Japanese. 

# %% [markdown]
# #### Top 10 cities with most restaurants

# %%
plt.figure(figsize=(11,6))
grouped = us_restaurants.city.value_counts()[:10]
sns.barplot(grouped.index, grouped.values, palette=sns.color_palette("GnBu_r", len(grouped)))
plt.ylabel('Number of restaurants', fontsize=14, labelpad=10)
plt.xlabel('City', fontsize=14, labelpad=10)
plt.title('Count of Restaurants by City (Top 10)', fontsize=15)
plt.tick_params(labelsize=14)
plt.xticks(rotation=15)
for  i, v in enumerate(grouped):
    plt.text(i, v*1.02, str(v), horizontalalignment ='center',fontweight='bold', fontsize=14)

# %% [markdown]
# #### Distribution of restaurants in each state

# %%
plt.figure(figsize=(11,6))
grouped = us_restaurants.state.value_counts()
sns.barplot(grouped.index, grouped.values,palette=sns.color_palette("GnBu_r", len(grouped)) )
plt.ylabel('Number of restaurants', fontsize=14)
plt.xlabel('State', fontsize=14)
plt.title('Count of Restaurants by State', fontsize=15)
plt.tick_params(labelsize=14)
for  i, v in enumerate(grouped):
    plt.text(i, v*1.02, str(v), horizontalalignment ='center', fontweight='bold', fontsize=14)

# %% [markdown]
# ### Reviews Distribution

# %% [markdown]
# #### Distribution of reviews by cuisine type

# %%
plt.figure(figsize=(11,7))
grouped = us_restaurants.groupby('category')['review_count'].sum().sort_values(ascending = False)
sns.barplot(y=grouped.index, x= grouped.values, palette= sns.color_palette("RdBu_r", len(grouped)) )
plt.ylabel('Category', fontsize=14)
plt.xlabel('Count of reviews', fontsize=14)
plt.title('Count of Reviews by Cuisine Type', fontsize=15)
for i,v in enumerate(grouped):
    plt.text(v, i+0.15, str(v),fontweight='bold', fontsize=14)
plt.tick_params(labelsize=14)

# %% [markdown]
# #### Top 10 cities with most reviews

# %%
plt.figure(figsize=(11,6))
grouped = us_restaurants.groupby('city')['review_count'].sum().sort_values(ascending=False)[:10]
sns.barplot(grouped.index, grouped.values, palette=sns.color_palette("GnBu_r", len(grouped)) )
plt.xlabel('City', labelpad=10, fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.title('Count of Reviews by City (Top 10)', fontsize=15)
plt.tick_params(labelsize=14)
plt.xticks(rotation=15)
for  i, v in enumerate(grouped):
    plt.text(i, v*1.02, str(v), horizontalalignment ='center',fontweight='bold', fontsize=14)

# %% [markdown]
# #### Top 9 restaurants with most reviews

# %%
plt.figure(figsize=(11,6))
grouped = us_restaurants[['name','review_count']].sort_values(by='review_count', ascending=False)[:9]
sns.barplot(x=grouped.review_count, y = grouped.name, palette=sns.color_palette("GnBu_r", len(grouped)), ci=None)
plt.xlabel('Count of Review', labelpad=10, fontsize=14)
plt.ylabel('Restaurants', fontsize=14)
plt.title('TOP 9 Restaurants with Most Reviews', fontsize=15)
plt.tick_params(labelsize=14)
plt.xticks(rotation=15)
for  i, v in enumerate(grouped.review_count):
    plt.text(v, i, str(v), fontweight='bold', fontsize=14)

# %% [markdown]
# #### Distribution of positive and negative reviews in each category

# %%
table = pd.pivot_table(restaurants_reviews, values=["review_id"], index=["category"],columns=["labels"], 
                       aggfunc=len, margins=True, dropna=True,fill_value=0)
table_percentage = table.div( table.iloc[:,-1], axis=0).iloc[:-1,-2].sort_values(ascending=False)

# %%
table = pd.pivot_table(restaurants_reviews, values=["review_id"], index=["category"],columns=["labels"], 
                       aggfunc=len, margins=True, dropna=True,fill_value=0)
table_percentage = table.div( table.iloc[:,-1], axis=0).iloc[:-1,-2].sort_values(ascending=False)
plt.figure(figsize=(11,8))
plt.subplot(211)
sns.pointplot(x=table_percentage.index, y= table_percentage.values)
plt.xlabel('Category', labelpad=7, fontsize=14)
plt.ylabel('Percentage of positive reviews', fontsize=14)
plt.title('Percentage of Positive Reviews', fontsize=15)
plt.tick_params(labelsize=14)
plt.xticks(rotation=40)
for  i, v in enumerate(table_percentage.round(2)):
    plt.text(i, v*1.001, str(v), horizontalalignment ='center',fontweight='bold', fontsize=14)
    
plt.subplot(212)
grouped = restaurants_reviews.groupby('category')['review_star'].mean().round(2).sort_values(ascending=False)
sns.pointplot(grouped.index, grouped.values)
plt.ylim(3)
plt.xlabel('Catagory', labelpad=10, fontsize=14)
plt.ylabel('Average Rating', fontsize=14)
plt.title('Average Rating of each Category', fontsize=15)
plt.tick_params(labelsize=14)
plt.xticks(rotation=40)
for  i, v in enumerate(grouped):
    plt.text(i, v, str(v), horizontalalignment ='center',fontweight='bold', fontsize=14)
    
plt.subplots_adjust(hspace=1)

# %% [markdown]
# #### Average length of reviews

# %% [markdown]
# #### Average length of words in each category

# %%
table = restaurants_reviews.groupby(['category','labels'])['num_words_review'].mean().round().unstack()
plt.figure(figsize=(11,8))
sns.heatmap(table, cmap='YlGnBu', fmt='g',annot=True, linewidths=1)
plt.tick_params(labelsize=15)

# %% [markdown]
# ### Ratings Distribution

# %% [markdown]
# #### Distribution of ratings by restaurants

# %%
plt.figure(figsize=(11,6))
grouped = us_restaurants.stars.value_counts().sort_index()
sns.barplot(grouped.index, grouped.values, palette=sns.color_palette("RdBu_r", len(grouped)))
plt.xlabel('Average Rating', labelpad=10, fontsize=14)
plt.ylabel('Count of restaurants', fontsize=14)
plt.title('Count of Restaurants against Ratings', fontsize=15)
plt.tick_params(labelsize=14)
for  i, v in enumerate(grouped):
    plt.text(i, v*1.02, str(v), horizontalalignment ='center',fontweight='bold', fontsize=14)

# %% [markdown]
# #### Distribution of ratings by reviews

# %%
plt.figure(figsize=(11,7))
grouped = restaurants_reviews.review_star.value_counts().sort_index()
sns.barplot(grouped.index, grouped.values, palette=sns.color_palette("RdBu_r", len(grouped)))
plt.xlabel('Review Rating', labelpad=10, fontsize=14)
plt.ylabel('Count of reviews', fontsize=14)
plt.title('Count of Reviews against Rating', fontsize=15)
plt.tick_params(labelsize=14)
for  i, v in enumerate(grouped):
    plt.text(i, v*1.02, str(v), horizontalalignment ='center',fontweight='bold', fontsize=14)

# %% [markdown]
# ## Review Analysis

# %% [markdown]
# ### Positive words and negative words

# %%
import csv
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import LinearSVC
pd.set_option('display.float_format', lambda x: '%.4f' % x)

# %%
## convert text to lower case
restaurants_reviews.text = restaurants_reviews.text.str.lower()

## remove unnecessary punctuation
restaurants_reviews['removed_punct_text']= restaurants_reviews.text.str.replace('\n',''). \
                                          str.replace('[!"#$%&\()*+,-./:;<=>?@[\\]^_`{|}~]','')


# %%
## import positive file which contains common meaningless positive words such as good
file_positive = open('positive.txt')
reader =csv.reader(file_positive)
positive_words = [word[0] for word in reader]

## import negative file which contains common meaningless positive words such as bad
file_negative = open('negative.txt')
reader =csv.reader(file_negative)
negative_words = [word[0] for word in reader]

# %%
## get dataset by category
def get_dataset(category):
    df = restaurants_reviews[['removed_punct_text','labels']][restaurants_reviews.category==category]
    df.reset_index(drop=True, inplace =True)
    df.rename(columns={'removed_punct_text':'text'}, inplace=True)
    return df



## only keep positive and negative words
def filter_words(review):
    words = [word for word in review.split() if word in positive_words + negative_words]
    words = ' '.join(words)
    return words

# %% [markdown]
# ### Use Korean as an example 

# %%
Korean_reviews = get_dataset('Korean')

# %%
Korean_train, Korean_test = train_test_split(Korean_reviews[['text','labels']],test_size=0.5)

# %%
print('Total %d number of reviews' % Korean_train.shape[0])

# %%
def split_data(dataset, test_size):
    df_train, df_test = train_test_split(dataset[['text','labels']],test_size=test_size)
    return df_train

# %%
## filter words
Korean_train.text = Korean_train.text.apply(filter_words)

# %%
## construct features and labels
terms_train=list(Korean_train['text'])
class_train=list(Korean_train['labels'])

terms_test=list(Korean_test['text'])
class_test=list(Korean_test['labels'])

# %%
## get bag of words : the frequencies of various words appeared in each review
vectorizer = CountVectorizer()
feature_train_counts=vectorizer.fit_transform(terms_train)
feature_train_counts.shape

# %%
## run model
svm = LinearSVC()
svm.fit(feature_train_counts, class_train)

# %% [markdown]
# Support Vector Machine (SVM) model was applied to differentiate positive and
# negative words in reviews, and further to get a word score to understand how positive or how negative the words are.

# %% [markdown]
# ### Now we can calculate polarity score of each word in the specific category

# %% [markdown]
# #### Korean

# %%
## create dataframe for score of each word in a review calculated by svm model
coeff = svm.coef_[0]
Korean_words_score = pd.DataFrame({'score': coeff, 'word': vectorizer.get_feature_names()})

# %%
## get frequency of each word in all reviews in specific category
Korean_reviews = pd.DataFrame(feature_train_counts.toarray(), columns=vectorizer.get_feature_names())
Korean_reviews['labels'] = class_train
Korean_frequency = Korean_reviews[Korean_reviews['labels'] =='positive'].sum()[:-1]

# %%
Korean_words_score.set_index('word', inplace=True)

# %%
Korean_polarity_score = Korean_words_score
Korean_polarity_score['frequency'] = Korean_frequency

# %% [markdown]
# ‘polarity score’ (a value that reflects the polarity of
# sentiment) towards each restaurant category, the sentiment
# score of each word was first multiplied by its frequency, and
# then normalized by the total number of reviews for the specific
# category of restaurants.
# 
# 𝑝𝑜𝑙𝑎𝑟𝑖𝑡𝑦_𝑠𝑐𝑜𝑟𝑒 𝑡, 𝑐 = 𝑠𝑐𝑜𝑟𝑒(𝑡)×
# 𝑡𝑜𝑡𝑎𝑙_𝑓𝑟𝑒𝑞𝑢𝑒𝑛𝑐𝑦(𝑡, 𝑐)
# 𝑛𝑢𝑚𝑏𝑒𝑟_𝑜𝑓_ 𝑟𝑒𝑣𝑖𝑒𝑤𝑠(𝑐)
# 
# 𝑝𝑜𝑙𝑎𝑟𝑖𝑡𝑦_𝑠𝑐𝑜𝑟𝑒 𝑡, 𝑐 is the index for measuring how
# essential word 𝑡 is among restaurants of type 𝑐
# 
# 𝑡𝑜𝑡𝑎𝑙_𝑓𝑟𝑒𝑞𝑢𝑒𝑛𝑐𝑦(𝑡, 𝑐) is the total frequency of word 𝑡 in
# all reviews of type 𝑐 restaurants
# 
# 𝑛𝑢𝑚𝑏𝑒𝑟_𝑜𝑓_ 𝑟𝑒𝑣𝑖𝑒𝑤𝑠(𝑐) is the total number of reviews of
# type 𝑐 restaurants.

# %%
## calculate polarity score 
Korean_polarity_score['polarity'] = Korean_polarity_score.score * Korean_polarity_score.frequency / Korean_reviews.shape[0]

# %% [markdown]
# since the SVM model actually calculate a total
# score for each review, and this score to some extent indicates
# how satisfied or discontented the customer is. The polarity
# score we calculated shows how much a word contributes to the
# score of all restaurants of a certain type. For example, the score
# of French restaurants is lowered by 0.15 in average due to
# ‘overpriced’ while is lowered by only 0.02 due to ‘dirty’. Then
# we might claim that ‘overpriced’ displeased customers a lot
# more than ‘dirty’, and thus ‘overpriced’ is a more essential
# (negative) characteristic of French restaurants.
# Then for each category of restaurants, the top positive and
# negative words are extracted. We may discover what are the
# special features for each type and the discrepancy of those
# restaurants providing great food around the world.

# %% [markdown]
# In order to find specific words that were used to indicate
# customers’ concerns for the restaurant, or by moving forward
# exploring the unique characteristic of each restaurant category,
# adjectives that simply describing the polarity of sentiment (i.e.
# “good”, “amazing”, “terrible” and etc.) were neglected.

# %%
## drop unnecessary words
unuseful_positive_words = Korean_polarity_score.loc[['great','amazing','love','best','awesome','excellent','good',
                                                    'favorite','loved','perfect','gem','perfectly','wonderful',
                                                    'happy','enjoyed','nice','well','super','like','better','decent','fine',
                                                    'pretty','enough','excited','impressed','ready','fantastic','glad','right',
                                                    'fabulous']]
unuseful_negative_words =  Korean_polarity_score.loc[['bad','disappointed','unfortunately','disappointing','horrible',
                                                     'lacking','terrible','sorry', 'disappoint']]

Korean_polarity_score.drop(unuseful_positive_words.index, axis=0, inplace=True)
Korean_polarity_score.drop(unuseful_negative_words.index, axis=0, inplace=True)

# %%
Korean_polarity_score.polarity = Korean_polarity_score.polarity.astype(float)
Korean_polarity_score.frequency = Korean_polarity_score.frequency.astype(float)

# %%
Korean_polarity_score[Korean_polarity_score.polarity>0].sort_values('polarity', ascending=False)[:20]

# %% [markdown]
# #### Get top 10 most informative positive and negative words

# %%
Korean_top_positive_words = ['delicious','friendly','attentive','recommend','fresh','variety','reasonable','tender','clean','authentic']
Korean_top_negative_words = ['bland','slow','expensive','overpriced', 'cold', 'greasy','sweet','fatty','rude','dirty']
Korean_top_words = Korean_polarity_score.loc[Korean_top_positive_words+Korean_top_negative_words,'polarity']

# %%
plt.figure(figsize=(11,6))
colors = ['red' if c < 0 else 'blue' for c in Korean_top_words.values]
sns.barplot(y=Korean_top_words.index, x=Korean_top_words.values, palette=colors)
plt.xlabel('Polarity Score', labelpad=10, fontsize=14)
plt.ylabel('Words', fontsize=14)
plt.title('TOP 10 Positive and Negative Words in Korean Restaurants', fontsize=15)
plt.tick_params(labelsize=14)
plt.xticks(rotation=15)

# %%
def get_polarity_score(dataset):
    dataset.text = dataset.text.apply(filter_words)
    
    terms_train=list(dataset['text'])
    class_train=list(dataset['labels'])
    
    ## get bag of words
    vectorizer = CountVectorizer()
    feature_train_counts=vectorizer.fit_transform(terms_train)
    
    ## run model
    svm = LinearSVC()
    svm.fit(feature_train_counts, class_train)
    
    ## create dataframe for score of each word in a review calculated by svm model
    coeff = svm.coef_[0]
    cuisine_words_score = pd.DataFrame({'score': coeff, 'word': vectorizer.get_feature_names()})
    
    ## get frequency of each word in all reviews in specific category
    cuisine_reviews = pd.DataFrame(feature_train_counts.toarray(), columns=vectorizer.get_feature_names())
    cuisine_reviews['labels'] = class_train
    cuisine_frequency = cuisine_reviews[cuisine_reviews['labels'] =='positive'].sum()[:-1]
    
    cuisine_words_score.set_index('word', inplace=True)
    cuisine_polarity_score = cuisine_words_score
    cuisine_polarity_score['frequency'] = cuisine_frequency
    
    cuisine_polarity_score.score = cuisine_polarity_score.score.astype(float)
    cuisine_polarity_score.frequency = cuisine_polarity_score.frequency.astype(int)
    
    ## calculate polarity score 
    cuisine_polarity_score['polarity'] = cuisine_polarity_score.score * cuisine_polarity_score.frequency / cuisine_reviews.shape[0]
    
    cuisine_polarity_score.polarity = cuisine_polarity_score.polarity.astype(float)
    ## drop unnecessary words
    unuseful_positive_words = ['great','amazing','love','best','awesome','excellent','good',
                                                   'favorite','loved','perfect','gem','perfectly','wonderful',
                                                    'happy','enjoyed','nice','well','super','like','better','decent','fine',
                                                    'pretty','enough','excited','impressed','ready','fantastic','glad','right',
                                                    'fabulous']
    unuseful_negative_words =  ['bad','disappointed','unfortunately','disappointing','horrible',
                                                    'lacking','terrible','sorry']
    unuseful_words = unuseful_positive_words + unuseful_negative_words
    cuisine_polarity_score.drop(cuisine_polarity_score.loc[unuseful_words].index, axis=0, inplace=True)
    
    return cuisine_polarity_score

# %%
def plot_top_words(top_words, category):
    plt.figure(figsize=(11,6))
    colors = ['red' if c < 0 else 'blue' for c in top_words.values]
    sns.barplot(y=top_words.index, x=top_words.values, palette=colors)
    plt.xlabel('Polarity Score', labelpad=10, fontsize=14)
    plt.ylabel('Words', fontsize=14)
    plt.title('TOP 10 Positive and Negative Words in %s Restaurants ' % category, fontsize=15)
    plt.tick_params(labelsize=14)
    plt.xticks(rotation=15)

# %%
def get_top_words(dataset, label, number=20):
    if label == 'positive':
        df = dataset[dataset.polarity>0].sort_values('polarity',ascending = False)[:number]
    else:
        df = dataset[dataset.polarity<0].sort_values('polarity')[:number]
    return df

# %% [markdown]
# #### Japanese

# %%
Japanese_reviews = get_dataset('Japanese')
Japanese_train = split_data(Japanese_reviews, 0.9)
print('Total %d number of reviews' % Japanese_train.shape[0])

# %%
Japanese_polarity_score = get_polarity_score(Japanese_train)

# %%
get_top_words(Japanese_polarity_score, 'positive')

# %%
get_top_words(Japanese_polarity_score,'negative',20)

# %%
Japanese_top_positive_words = ['delicious','friendly','fresh','recommend','fun','reasonable',
                               'creative','clean','variety','attentive']
Japanese_top_negative_words = ['hard','cold','wrong','slow','bland','dark','expensive',
                               'rude','overpriced','crowded']
Japanese_top_words = Japanese_polarity_score.loc[Japanese_top_positive_words+Japanese_top_negative_words,'polarity']

# %%
plot_top_words(Japanese_top_words,'Japanese')

# %% [markdown]
# #### Thai

# %%
Thai_reviews = get_dataset('Thai')
Thai_train = split_data(Thai_reviews, 0.8)
print('Total %d number of reviews' % Thai_train.shape[0])

# %%
Thai_polarity_score = get_polarity_score(Thai_train)

# %%
get_top_words(Thai_polarity_score,'positive')

# %%
get_top_words(Thai_polarity_score,'negative')

# %%
Thai_top_positive_words = ['delicious','friendly','fresh','recommend','reasonable','affordable','variety',
                           'attentive','fast','comfortable']
Thai_top_negative_words = ['bland','greasy','expensive','weird','wrong','slow','hard','cold','sour','mushy','mess']
Thai_top_words = Thai_polarity_score.loc[Thai_top_positive_words+Thai_top_negative_words,'polarity']
plot_top_words(Thai_top_words, 'Thai')

# %% [markdown]
# #### Chinese

# %%
Chinese_reviews = get_dataset('Chinese')
Chinese_train = split_data(Chinese_reviews, 0.85)
print('Total %d number of reviews' % Chinese_train.shape[0])

# %%
Chinese_polarity_score = get_polarity_score(Chinese_train)

# %%
get_top_words(Chinese_polarity_score,'positive')

# %%
get_top_words(Chinese_polarity_score,'negative')

# %%
Chinese_top_positive_words = ['delicious','friendly','fresh','authentic','reasonable','hot','fun',
                           'fast','tender','recommend']
Chinese_top_negative_words = ['sour','bland','cold','greasy','hard','slow','wrong','rude','overpriced','frozen']
Chinese_top_words = Chinese_polarity_score.loc[Chinese_top_positive_words+Chinese_top_negative_words,'polarity']
plot_top_words(Chinese_top_words, 'Chinese')

# %% [markdown]
# #### Vietnamese

# %%
Vietnamese_reviews = get_dataset('Vietnamese')
Vietnamese_train = split_data(Vietnamese_reviews, 0.7)
print('Total %d number of reviews' % Vietnamese_train.shape[0])

# %%
Vietnamese_polarity_score = get_polarity_score(Vietnamese_train)

# %%
get_top_words(Vietnamese_polarity_score,'positive')

# %%
get_top_words(Vietnamese_polarity_score,'negative')

# %%
Viet_top_positive_words = ['delicious','fresh','clean','fast','recommend','reasonable','tender',
                           'fancy','refreshing','generous']
Viet_top_negative_words = ['bland','wrong','hard','slow','expensive','rude','greasy','dirty','weird','smelled']
Viet_top_words = Vietnamese_polarity_score.loc[Viet_top_positive_words+Viet_top_negative_words,'polarity']
plot_top_words(Viet_top_words,'Viet')

# %% [markdown]
# #### French

# %%
French_reviews = get_dataset('French')
French_train = split_data(French_reviews, 0.7)
print('Total %d number of reviews' % French_train.shape[0])

# %%
French_polarity_score = get_polarity_score(French_train)

# %%
get_top_words(French_polarity_score,'positive')

# %%
get_top_words(French_polarity_score, 'negative')

# %%
French_top_positive_words = ['delicious','sweet','tender','impeccable','recommend','rich','attentive',
                             'beautifully','crisp','romantic']
French_top_negative_words = ['cold','expensive','slow','bland','overpriced','mediocre','wrong',
                             'poor','squash','knife']
French_top_words = French_polarity_score.loc[French_top_positive_words+French_top_negative_words,'polarity']
plot_top_words(French_top_words,'French')

# %% [markdown]
# #### Italian

# %%
Italian_reviews = get_dataset('Italian')
Italian_train = split_data(Italian_reviews, 0.9)
print('Total %d number of reviews' % Italian_train.shape[0])

# %%
Italian_polarity_score = get_polarity_score(Italian_train)

# %%
get_top_words(Italian_polarity_score, 'positive',30)

# %%
get_top_words(Italian_polarity_score, 'negative',30)

# %%
Italian_top_positive_words = ['delicious','fresh','friendly','recommend','reasonable','authentic',
                             'attentive','fun','refreshing','classic']
Italian_top_negative_words = ['cold','hard','wrong','bland','expensive','slow','greasy','fried','frozen','dirty']
Italian_top_words = Italian_polarity_score.loc[Italian_top_positive_words+Italian_top_negative_words,'polarity']
plot_top_words(Italian_top_words,'Italian')

# %% [markdown]
# ### Combine all top words to compare among different cuisine typies

# %%
all_category = {'cuisine':['Korean','Japanese','Chinese','Thai','Vietnamese','French','Italian']}
cuisine_positive_words = pd.DataFrame(all_category)
for i,word in enumerate(Korean_top_positive_words):
    cuisine_positive_words.loc[0,i] = word

# %%
for i,word in enumerate(Korean_top_positive_words):
    cuisine_positive_words.iloc[0,i] = word
for i,word in enumerate(Japanese_top_positive_words):
    cuisine_positive_words.iloc[1,i] = word
for i,word in enumerate(Chinese_top_positive_words):
    cuisine_positive_words.iloc[2,i] = word
for i,word in enumerate(Thai_top_positive_words):
    cuisine_positive_words.iloc[3,i] = word
for i,word in enumerate(Viet_top_positive_words):
    cuisine_positive_words.iloc[4,i] = word
for i,word in enumerate(French_top_positive_words):
    cuisine_positive_words.iloc[5,i] = word
for i,word in enumerate(Italian_top_positive_words):
    cuisine_positive_words.iloc[6,i] = word

cuisine_positive_words.drop(9,axis=1,inplace=True)
cuisine_positive_words.columns=['0','1','2','3','4','5','6','7','8','9']
cuisine_positive_words['cuisine']=['Korean','Japanese','Chinese','Thai','Vietnamese','French','Italian']
cuisine_positive_words.set_index('cuisine', inplace=True)

# %%
all_category = {'cuisine':['Korean','Japanese','Chinese','Thai','Vietnamese','French','Italian']}
cuisine_negative_words = pd.DataFrame(all_category)
for i,word in enumerate(Korean_top_negative_words):
    cuisine_negative_words.loc[0,i] = word

# %%
for i,word in enumerate(Korean_top_negative_words):
    cuisine_negative_words.iloc[0,i] = word
for i,word in enumerate(Japanese_top_negative_words):
    cuisine_negative_words.iloc[1,i] = word
for i,word in enumerate(Chinese_top_negative_words):
    cuisine_negative_words.iloc[2,i] = word
for i,word in enumerate(Thai_top_negative_words):
    cuisine_negative_words.iloc[3,i] = word
for i,word in enumerate(Viet_top_negative_words):
    cuisine_negative_words.iloc[4,i] = word
for i,word in enumerate(French_top_negative_words):
    cuisine_negative_words.iloc[5,i] = word
for i,word in enumerate(Italian_top_negative_words):
    cuisine_negative_words.iloc[6,i] = word

cuisine_negative_words.drop(9,axis=1,inplace=True)
cuisine_negative_words.columns=['0','1','2','3','4','5','6','7','8','9']
cuisine_negative_words['cuisine']=['Korean','Japanese','Chinese','Thai','Vietnamese','French','Italian']
cuisine_negative_words.set_index('cuisine', inplace=True)

# %%
cuisine_positive_words

# %%
cuisine_negative_words

# %% [markdown]
# # 6. Findings

# %% [markdown]
# In general, We found out that for most restaurant types, delicious ranks first among all positive words, indicating that tastes might weight more than other factors like service and price when people are judging a restaurant. For most cuisine types, the word friendly rank first before the word reasonable, which means the friendly service is more likely to be the reason for the high score rather than reasonable price. It could also be observed that when it comes to the flavor of food, customers value freshness more than tastiness. 

# %% [markdown]
# Different characteristics are also shown for different restaurant categories. Vietnamese and Italian food received
# positive feedback because of freshness, while French restaurants received positive reviews for their sweet food. However, sweet food is the reason for Korean restaurants to have negative reviews. Korean, Japanese, Chinese, and Thai have positive reviews mainly for their friendly service, especially for Korean restaurants, since attentive ranks third. The variety of food is also the reason of high score for Korean, Japanese and Thai cuisine types. Fun and creative are special charateristics for Japanese restaurants. For Italian cuisine type, customers prefer classic Italian food. The reason of high score in French cuisine type is related to the romantic and beautiful appearence or environment.

# %% [markdown]
# From the negative word list, we could observe that bland is one of the main problems for Korean, Thai and Vietnamese restaurants, which means customers expect food of those three cuisine type should be spicy. For French, Italian and Japanese cuisine types of restaurants, it is likely to have the low score because the food is cold. The low score of Japanese cuisine type is also due to the dark and crowded environment. Sour is one of the main problems for Chinese cuisine type. Slow service is the main negative characteristic for Korean and French. French cuisine type receive negative reviews also for the expensive price. Thai receive negative reviews mainly for greasy food.

# %% [markdown]
# Since our analysis may help to extract specific features from
# any set of reviews, restaurant owners can make good use of it
# for essential information once they received a certain amount
# of Yelp reviews. From those reviews they can understand why
# customers love or dislike their restaurants, maybe great reviews
# primarily due to fresh food, or perhaps unsatisfied reviews
# caused by too high price. Meanwhile they can also compare the
# restaurant with similar restaurants within the same type.

# %% [markdown]
# # 7. Recommendation

# %% [markdown]
# ## Korean

# %% [markdown]
# For food, prioritize taste as the most important selling point. Pay more attention to using fresh ingredients and keeping tender texture of meat. Control the cooking process to prevent greasy or too sweet, but do not lose flavor. It might be helpful to make some creations on dishes and make it look authentically attractive;<br>
# For service, invest on waiters/waitress training. Make them highly professional in servicing customers, avoiding mistakes such as serving wrong food and paying more attention to caring customers all the time. Make sure they are friendly and nice to customers;<br>
# For marketing strategy, invest on advertisement on social media and adjust price if overpriced. Make creation in menu and increase the variety to attract customers. And keep the environment clean. Make adjustment on price if it is overpriced.

# %% [markdown]
# ## Japanese

# %% [markdown]
# For food, except prioritizing cooking food delicious, using fresh ingredients is extremely important for Japanese restaurants. Besides, they can make creations on traditional food in order to attract customers and increase varieties of dishes in menu; 
# 
# For service, train the waiters to provide friendly and attentive care for customers and avoid mistakes such as serving wrong food; 
# 
# For management, to those restaurants serving raw Japanese dish, we highly recommend that they can invest on technology to protect ingredients fresh or shorten the transportation time to avoid spoilage. Keep cleaning environment and fun. Make corresponding change according to customers feedback such as what are their feelings to the surroundings like the lighting, air condition temperature or the decoration. If there was too crowded, try to enlarge the dining area or redesign the table. Setting reasonable price and make adjustments on highly expensive price could also attract customers.

# %% [markdown]
# ## Chinese

# %% [markdown]
# For Chinese restaurants, delicious and authentic food is more likely to receive high-rating reviews so tasty is always at the first place. People also like hot taste but not too sour or bland. And restaurants can make some improvements on cooking way especially for the greasy cuisine and it is great to use fresh ingredients.
# 
# For service, restaurants can train waiters to perform nice, fast and professional service. In order to attract more customers, reasonable price is also important.

# %% [markdown]
# ## Thai

# %% [markdown]
# Tasty food is the priority.  For Thai food, people like fresh taste but not too sour or too bland. They appreciate food with high variety. And they seem not like mushy or greasy. It is also necessary to see if some food taste weird for local customers;<br>
# 
# For service, besides some common requirements such as friendly and attentive service, customers also like fast and hate waiting because of ‘slow’ service;<br>
# 
# For management, customer like reasonable price and comfortable environment.
# 

# %% [markdown]
# ## Vietnamese

# %% [markdown]
# For Vietnam restaurants, beside some common requirements, people gave high reviews to some about their clean and fancy environment. But they also complain about dirty ones. So, there may diverse conditions in restaurants which dirty ones can learn from it and know where they need to improve. Reasonable price is popular factor to influence their reviews as well.
# 
# Speaking of food, customer like tender taste and they like when restaurants serve generously. It may be a good way to attract customers. And they also like fresh and do not like greasy or bland.
# 
# For service, it seems there are serious issues about wrong and slow service. Even ‘rude’ came much more frequently than other types. So, providing good service and having nice and professional waiters are significant.
# 

# %% [markdown]
# ## French

# %% [markdown]
# For Vietnam restaurants, beside some common requirements, people gave high reviews to some about their clean and fancy environment. But they also complain about dirty ones. So, there may diverse conditions in restaurants which dirty ones can learn from it and know where they need to improve.
# 
# Speaking of food, customer like tender taste and they like when restaurants serve generously. It may be a good way to attract customers. And they also like fresh and do not like greasy or bland.
# 
# For service, it seems there are serious issues about wrong and slow service. Even ‘rude’ came much more frequently than other types. So, providing good service and having nice and professional waiters are significant.
# 

# %% [markdown]
# ## Italian 

# %% [markdown]
# For Vietnam restaurants, beside some common requirements, people gave high reviews to some about their clean and fancy environment. But they also complain about dirty ones. So, there may diverse conditions in restaurants which dirty ones can learn from it and know where they need to improve.
# 
# Speaking of food, customer like tender taste and they like when restaurants serve generously. It may be a good way to attract customers. And they also like fresh and do not like greasy or bland.
# 
# For service, it seems there are serious issues about wrong and slow service. Even ‘rude’ came much more frequently than other types. So, providing good service and having nice and professional waiters are significant.
# 


